{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahmoudKhaledd/Data-Modeling-with-Postgres/blob/main/survey_cleaning_combined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guidelines:\n",
        "* Upload qualitrics / inc-query data, main task, and call task data files to the 'content' folder on the left, by clicking the three dots and choosing 'upload file'\n",
        "\n",
        "* Enter the survey type ('qual' or 'inc')\n",
        "* Enter filenames as they are without the \".xlsx\"\n",
        "* Enter column names between single quotations seperated by a comma, and don't remove the brackets [ ]\n",
        "\n",
        "* **brands_question** > Enter exact column name if all brands are in the same cell, or enter the question number, for example Q17, and it will scan the rest (Q17_1, Q17_2, etc) if each brand in a different cell\n",
        "\n",
        "* **text_questions** >\n",
        "   * **Qualtrics**: Enter column name complete, for example: \"Q17_1\"\n",
        "   * **Inc-Query**: Just enter the column number, for example \"Q45\", script will scan the rest\n",
        "\n",
        "* **straighlining_questions** > Enter column name without the \"_\" and it will scan the rest.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "______________________________________________________________________\n",
        "\n",
        "\n",
        "# Risk Score Calculations:\n",
        "* **Duration < min** = +100\n",
        "* **Duration > max** = +30\n",
        "* **Straightlining** = +40\n",
        "* **Text Duplication** = +100\n",
        "* **Risk Rating**  \"High\" = +20\n",
        "* **User IP Countries** > 1 = +50\n",
        "* **Shared PayPal Accounts** > 1 = +100\n",
        "* **Honesty Rating** < 10 AND (Lifetime Accepted Count + Lifetime DisqualificationCount > 50) = +10\n",
        "* **User VPN Usage** > 50 = +100\n",
        "\n",
        "\n",
        "\n",
        "______________________________________________________________________\n",
        "# Notes\n",
        "\n",
        "* In addition to the \"Risk Score Calculations\", the script dies the following:\n",
        "  * Combines the inc-query / uqaltrics data with the pulse main and call tasks into one excel file.\n",
        "  * Highlights the \"good\" users in green and the \"bad\" users in red.\n",
        "  * Highlights if the \"User Honesty Rating\" is less than 51\n",
        "  * Highlights the straightlined answers.\n",
        "  * Highlights the duplicated answers.\n",
        "  * If gc=0: (**Qualtrics Only**) \n",
        "    * Highlights the \"Risk Score\" in orange and label it as \"rejected by screeners\"\n",
        "    * Action to Client will be \"Rejected by Script\"\n",
        "    * Reason will be \"gc=0\".\n",
        "  * If duration is less than the mininmum threhold entered by user:\n",
        "    * \"Action to client\" will be \"Rejected by Script\"\n",
        "    * \"Reason\" will be \"Speeder\" \n",
        "* Adds \"Comments\" column for all the violations present in the survey.\n"
      ],
      "metadata": {
        "id": "lw6TNeAHEDIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p9Km4dJHSozB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c65a172-d3db-4ee5-8d67-eb8a46757ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.97)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.24.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "########################################################### EDIT HERE ##################################################################\n",
        "\n",
        "# Enter 'inc' or 'qual'\n",
        "survey_type = 'qual' \n",
        "\n",
        "main_task_filename = \"MainSSG\" # Enter without the \".xlsx\" or \".csv\"\n",
        "call_task_filename = \"CallSSG\" # Enter without the \".xlsx\" or \".csv\"\n",
        "qual_or_inc_filename = \"QualSSG\" # Enter without the \".xlsx\" or \".csv\"\n",
        "\n",
        "# Enter the minimum and maximum duration threholds in minutes\n",
        "min_duration_allowed_in_mins = 7\n",
        "max_duration_allowed_in_mins = 1000\n",
        "# Enter column name complete if all brands are in the same cell\n",
        "# or enter column name without the prefix after the \"_\" if brands are in\n",
        "# different cells|\n",
        "brands_questions = ['Q17']\n",
        "# Enter column name complete\n",
        "text_questions = ['Q16','Q27','Q28']\n",
        "# Enter column name without the prefix after the \"_\"\n",
        "straightlineing_questions = []\n",
        "# Enter column name complete\n",
        "outliers_questions = []\n",
        "\n",
        "# DO NOT EDIT BELOW\n",
        "#######################################################################################################################################\n",
        "#######################################################################################################################################\n",
        "#######################################################################################################################################\n",
        "#######################################################################################################################################\n",
        "#######################################################################################################################################\n",
        "\n",
        "# changes made on 22/09/2022 by Carlos:\n",
        "# changed the text duplicates section to make the runs more efficient, and it also spots text similarities instead of only duplicates\n",
        "#######################################################################################################################################\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from openpyxl import load_workbook\n",
        "!pip install -U sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "def clean_headers(s):\n",
        "  #Extracts question numbers from headers, for example: Q1, Q19, etc.\n",
        "  try:\n",
        "    r = re.findall('Q[0-9]+', s)[0]\n",
        "    return r  \n",
        "  except:\n",
        "    return s\n",
        "\n",
        "\n",
        "def rename(l):\n",
        "  \"\"\"\n",
        "  Renames the duplicate question names so:\n",
        "  ['Q1', 'Q1', 'Q1'] -> ['Q1_1', 'Q1_2', 'Q1_3']\n",
        "  \"\"\"\n",
        "  seen = {}\n",
        "  total = {}\n",
        "  for x in l:\n",
        "      if x not in total:\n",
        "        total[x] = l.count(x)\n",
        "  for x in l:\n",
        "    if x in seen:\n",
        "        seen[x] += 1\n",
        "        yield \"%s_%d\" % (x, seen[x])\n",
        "    elif x not in seen and total[x] > 1:\n",
        "      seen[x] = 1\n",
        "      yield \"%s_1\" % x\n",
        "    else:\n",
        "        yield x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def set_duration_criteria(x):\n",
        "  if(x < 10):\n",
        "    return \"< 10% of average\"\n",
        "  if(x < 25):\n",
        "    return \"10%-25% of average\"\n",
        "  if(x < 50):\n",
        "    return \"25%-50% of average\"\n",
        "  if(x < 75):\n",
        "    return \"50%-75% of average\"\n",
        "  if(x < 90):\n",
        "    return \"75%-90% of average\"\n",
        "  else:\n",
        "    return \"> 90% of average\"\n",
        "\n",
        "\n",
        "\n",
        "def read_file(filename):\n",
        "  # Reads the file whether it's an excel or csv\n",
        "  try:\n",
        "    df = pd.read_excel(\"{}.xlsx\".format(filename))\n",
        "  except:\n",
        "    df = pd.read_csv(\"{}.csv\".format(filename))\n",
        "  return df\n",
        "\n",
        "def clean_text(text):\n",
        "  # Takes a str, returns it cleaned\n",
        "  # remove numbers\n",
        "  try:\n",
        "    clean_text = ''.join([i for i in text if not i.isdigit()])\n",
        "    # remove panctuation\n",
        "    clean_text = re.sub(r'[^\\w\\s]','',clean_text)\n",
        "    # remove spaces at the end, and converts to lowercase\n",
        "    return clean_text.strip().lower()\n",
        "  except:\n",
        "    None\n",
        "\n",
        "def straightline(MyList):\n",
        "  \"\"\" \n",
        "  Takes a list, returns how many times the most frequent element appears\n",
        "  eg. [1,2,3,4,4] > 2\n",
        "    [1,2,3,4] > 0 (no most frequent element)\n",
        "  \"\"\"\n",
        "  res = {}\n",
        "  for i in MyList:\n",
        "      res[i] = MyList.count(i)\n",
        "  result = max(list(res.values()))\n",
        "  if result == 1:\n",
        "    result = 0     \n",
        "  return(result)\n",
        "\n",
        "\n",
        "\n",
        "def country_check(row):\n",
        "  \"\"\"\n",
        "  Takes a df row, checks if Country equals or is in User IP Countries,\n",
        "  if so, returns GOOD, else BAD\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if row[\"country\"] in row[\"User IP Countries\"]:\n",
        "      return \"GOOD\"\n",
        "    else:\n",
        "      return \"BAD\"\n",
        "  except:\n",
        "    None\n",
        "\n",
        "\n",
        "def change_type(x):\n",
        "    # Changes the type to float. If NULL, do nothing\n",
        "    try:\n",
        "        return float(x)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "\n",
        "def move_column(df, pos, col_name):\n",
        "  \"\"\" \n",
        "  Takes in the dataframe, position we want to move the column to,\n",
        "  and column name, and moves it to this position\n",
        "  \"\"\"\n",
        "  cols = list(df)\n",
        "  cols.insert(pos, cols.pop(cols.index('{}'.format(col_name))))\n",
        "  df = df.loc[:, cols]\n",
        "  return df\n",
        "\n",
        "def color_cell(idx, col, color):\n",
        "  \"\"\" \n",
        "  Takes the index, column name, and the required color to color\n",
        "  a specefic cell\n",
        "  \"\"\"\n",
        "  color = 'background-color: {}'.format(color)\n",
        "  df1.loc[idx, col] = color\n",
        "\n",
        "\n",
        "def return_df1(x):  \n",
        "  \"\"\" \n",
        "  This is required for df.style.apply as it takes in a function that\n",
        "  returns the styler dataframe in order to style the main one:\n",
        "  df.style.apply(return_df1)\n",
        "  \"\"\"\n",
        "  return df1\n",
        "\n",
        "\n",
        "# Read files into dataframes\n",
        "df_main = read_file(main_task_filename)\n",
        "df_call = read_file(call_task_filename)\n",
        "df_ = read_file(qual_or_inc_filename)\n",
        "\n",
        "if survey_type == 'inc':\n",
        "  # Adjust columns and headers format\n",
        "  df_[\"Duration (in seconds)\"] = df_[\"End time (GMT)\"] - df_[\"Start time (GMT)\"]\n",
        "  df_[\"Duration (in seconds)\"] = df_[\"Duration (in seconds)\"].dt.total_seconds()\n",
        "  questions_inc = df_.columns.to_list()\n",
        "  a_dict = pd.Series(questions_inc, index = df_.columns).to_dict()\n",
        "  new_df = pd.DataFrame(a_dict, index = [0])\n",
        "  df_ = new_df.append(df_).reset_index(drop = True)\n",
        "  headers = list(df_.columns)\n",
        "  headers_cleaned = list(map(clean_headers, headers))\n",
        "  headers_cleaned = list(rename(headers_cleaned))\n",
        "  df_.columns = headers_cleaned\n",
        "\n",
        "# Append main and call task dataframes\n",
        "df_tasks = df_main.append(df_call)\n",
        "\n",
        "\n",
        "# The list of the columns needed from call and main task to be kept.\n",
        "cols = [\"Response Id\", \"Task Id\", \"Task Type\", \"User Id\", \"User Honesty Rating\",\n",
        "        \"Risk Rating\", \"User Acquisition Source\", \"User Acquisition Campaign\",\n",
        "        \"state\", \"Comment\", \"Status Reason\", \"Previous Comment\", \"country\",\n",
        "        \"User IP Countries\", \"industry\", \"User Role\", \"Seniority\",\n",
        "        \"Shared IP Users\", \"Shared PayPal Account\", \"User Distinct IP Count\", \n",
        "        \"User IP Different From Registration Country\", \"User VPN Usage Count\", \n",
        "        \"User Tor Usage Count\", \"Task Accepted Count\", \"Task Declined Count\", \n",
        "        \"Task Disqualification Count\", \"Failed Trick Questions\", \n",
        "        \"Lifetime Accepted Count\", \"Lifetime Declined Count\", \"Task Name\", \n",
        "        \"Lifetime Disqualification Count\", \"Lifetime Failed Trick Questions\"]\n",
        "\n",
        "users_data = [['0b9dfc1a-e5ed-44e9-b789-3a3d5c2a0bc2', 'James', 'Good'], \\\n",
        "              ['d9ec5b93-c2ae-454a-be62-cf0a69f08e71', 'Jersham', 'Good'], \\\n",
        "              ['40bdf3a8-e067-49bf-bccd-76a54625d11f', 'leonard mbrice', 'Good'], \\\n",
        "              ['6d335372-1bff-473b-97cb-3bcf10772272', 'ruslan nikolayenko', 'Good'], \\\n",
        "              ['f45f7d5b-92e1-41bb-86e1-66209a0d6eea', 'paniz', 'Good'], \\\n",
        "              ['5d50cb51-95e8-4fbe-82ba-6bad4b88f3de', 'Loreno', 'Good'], \\\n",
        "              ['d03dde68-0e5d-43ec-a1a6-4885838e571b', 'Herve', 'Good'], \\\n",
        "              ['18b7d0eb-483b-4c1d-8600-86e4bc8c190a', 'Gerti', 'Good'], \\\n",
        "              ['fcc812bd-2a2d-42a6-aed9-d8fc92d88fa7', 'Louis', 'Good'], \\\n",
        "              ['8664b72b-4328-4633-a09b-ec35a7227911', 'Primael Tindano', 'Good'], \\\n",
        "              ['2f428603-d574-4421-8cf3-2d989827b0ef', 'Kamela', 'Good'], \\\n",
        "              ['c7de7441-cf3c-48d0-8763-c5515e7c9997', 'Ledina', 'Good'], \\\n",
        "              ['3bc4df0f-74dc-45c2-9aac-cee40d0bd51c', 'cedric', 'Good'], \\\n",
        "              ['cc599d45-1ce6-4a09-9e60-0439083af294', 'giada', 'Good'], \\\n",
        "              ['a5989e95-5887-456a-9e59-6bdea3fe11f7', 'Elina', 'Good'], \\\n",
        "              ['6af15730-4a24-4386-80c5-82b0317b3c4d', 'Guira', 'Good'], \\\n",
        "              ['05659cf3-20f1-4454-8a42-2b7f03011d58', 'Leonard', 'Good'], \\\n",
        "              ['90f08520-1fd5-4535-8cf4-631530377e4f', 'Junior', 'Good'], \\\n",
        "              ['a62a06e9-df64-4db6-bdc5-ebfe35655d9e', 'Frank ', 'Good'], \\\n",
        "              ['34a19a6c-1b0f-4fd2-88af-2e5a90789583', 'Alla', 'Good'], \\\n",
        "              ['44ab9b66-7c86-4ac9-bbe6-99e6d5864e4a', 'Alla', 'Good'], \\\n",
        "              ['d6f90cab-a4c7-4275-9b44-c976dec3dbe8', 'Eris', 'Good'], \\\n",
        "              ['1cb60d01-5f11-42ad-a989-5973ad00f7e5', 'Max', 'Good'], \\\n",
        "              ['447907bf-f4d2-4e70-917e-4b67256988dc', 'Mark Alberto', 'Bad'], \\\n",
        "              ['6deeb122-487d-435a-9ecf-7b455aac388f', 'Jennifer Endres', 'Bad'], \\\n",
        "              ['c93f951e-4eb5-4629-b783-ffecb36fd735', 'saadatu yakubu', 'Bad'], \\\n",
        "              ['d5f77216-614c-43cb-ae66-cfce326957e9', 'eugene Paradero', 'Bad'], \\\n",
        "              ['4fa9555f-62fb-4d4e-abb4-2f4130dfb88d', 'Rutchi Chiong', 'Bad'], \\\n",
        "              ['527d7951-6e58-4434-bbf1-500f4a3f18a5', 'Vesna Djordjevic', 'Bad'], \\\n",
        "              ['601121d0-6150-41a7-a6ea-41fcd58ddb3b', 'Alessandro Marchi', 'Bad'], \\\n",
        "              ['e73520c6-1b84-49c7-a1f7-abe8d2758391', 'Lara M', 'Bad'], \\\n",
        "              ['47ff9ce0-2e49-42d9-b454-f3b24cc91039', 'Rose Fiona', 'Bad'], \\\n",
        "              ['2f1f890e-abd7-4a36-bf13-cd01dca8055f', 'Egir Cela', 'Bad'], \\\n",
        "              ['695583f3-654b-4e45-8ee4-d1f7b54627fd', 'Julia Bracco', 'Bad'], \\\n",
        "              ['581134d4-f88c-47c8-ad29-4701557b98eb', 'Fatima', 'Bad'], \\\n",
        "              ['b58a3261-13dd-47d0-bad6-7445fe470b05', 'Fatima', 'Bad'], \\\n",
        "              ['ee0275a9-665c-43e5-a14d-e50424c5de87', 'Fatima', 'Bad'], \\\n",
        "              ['37b6c2f7-4429-4326-93c4-c04a792e13c9', 'Philopatir', 'Bad'], \\\n",
        "              ['dcd37616-28b5-4852-a16d-44dcc7ae74af', 'Philopatir', 'Bad'], \\\n",
        "              ['bdbd6768-5e19-4b2b-bf7a-465a724c86e9', 'Fatimas friend', 'Bad']] \n",
        "\n",
        "# Create the users dataframe\n",
        "\n",
        "df_users = pd.DataFrame(users_data, columns=['user_id', 'user_name', 'user_status'])\n",
        "\n",
        "\n",
        "# Keeping an original list of the cols before we modify cols \n",
        "pulse_cols = cols\n",
        "\n",
        "# Remove all columns from df_tasks but only keep te pulse cols\n",
        "df_tasks = df_tasks[cols]\n",
        "\n",
        "\n",
        "# Perform the country check\n",
        "df_tasks[\"Country Check\"] = \\\n",
        "df_tasks.apply(lambda row: country_check(row), axis=1)\n",
        "\n",
        "# Move the Country Check column to the required position\n",
        "df_tasks = move_column(df_tasks, 13, \"Country Check\")\n",
        "\n",
        "if survey_type == 'inc':\n",
        "  # Merge df tasks and df qualtrics on response ID as a new df\n",
        "  df = df_tasks.merge(df_, how = \"right\", \\\n",
        "                    right_on = \"Respondent\", left_on = \"Response Id\")\n",
        "else:\n",
        "  # Merge df tasks and df qualtrics on response ID as a new df\n",
        "  df = df_tasks.merge(df_, how = \"right\", \\\n",
        "                    right_on = \"responseId\", left_on = \"Response Id\")\n",
        "  # If \"GC\" is uppercase, make it lower case to be used further\n",
        "  df.rename(columns={\"GC\":\"gc\"}, inplace = True)\n",
        "\n",
        "  # Move gc column to the start of the file\n",
        "  df = move_column(df, 0, 'gc')\n",
        "\n",
        "\n",
        "# Change the type of the duration column into float\n",
        "df[\"Duration (in seconds)\"] = \\\n",
        "df['Duration (in seconds)'].apply(change_type).dropna()\n",
        "# Converting the duration in seconds into minutes\n",
        "df[\"Duration (in minutes)\"] = df[\"Duration (in seconds)\"] / 60\n",
        "\n",
        "# Move the duration in minutes column to the required position\n",
        "df = move_column(df, 33, \"Duration (in minutes)\")\n",
        "\n",
        "# Create three empty columns\n",
        "df[\"Pulse Action\"] = \"\"\n",
        "df[\"Action to Client\"] = \"\"\n",
        "df[\"Reason\"] = \"\"\n",
        "\n",
        "# Move columns around to their required position\n",
        "df = move_column(df, 34, \"Reason\")\n",
        "df = move_column(df, 34, \"Action to Client\")\n",
        "df = move_column(df, 34, \"Pulse Action\")\n",
        "df = move_column(df, 15, \"Country Check\")\n",
        "df = move_column(df, 4, \"Task Name\")\n",
        "# Merging with users df\n",
        "df = df.merge(df_users, how = 'left', left_on = 'User Id', right_on = 'user_id').drop(columns = [\"user_id\"])\n",
        "\n",
        "# Moving columsn around\n",
        "df = move_column(df, 5, 'user_status')\n",
        "df = move_column(df, 5, 'user_name')\n",
        "\n",
        "# Reset index of the main df\n",
        "df = df.reset_index().drop(columns = [\"index\"])\n",
        "\n",
        "# Extracting the question row now as it'll mess up our analysis later\n",
        "questions_row = df.iloc[0]\n",
        "# Initialzie the styler dataframe df1, to be used to color cells\n",
        "df1 = pd.DataFrame('', index=df.index, columns=df.columns)\n",
        "# Drop the question row\n",
        "df = df.drop(0, axis = 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Making a new df with no duration outliers to be used to calcualte the avg\n",
        "q_low = df[\"Duration (in seconds)\"].quantile(0.01)\n",
        "q_hi  = df[\"Duration (in seconds)\"].quantile(0.99)\n",
        "df_no_outliers = df[(df[\"Duration (in seconds)\"] < q_hi) & \\\n",
        "                    (df[\"Duration (in seconds)\"] > q_low)]\n",
        "\n",
        "# Calculating the average duration of the survey, no outliers are taken into\n",
        "# consideration\n",
        "avg_duration = df_no_outliers[\"Duration (in seconds)\"].mean()\n",
        "\n",
        "\n",
        "# Calculating the percentage of average for each record\n",
        "df[\"Duration_Percentage_of_Average ({} mins)\".format(avg_duration/60)] = \\\n",
        "df[\"Duration (in seconds)\"].apply(lambda x: x/avg_duration*100)\n",
        "\n",
        "# Adding a column for the average duration criteria based on average duration\n",
        "df[\"Duration_Criteria\"] = df[\"Duration_Percentage_of_Average ({} mins)\". \\\n",
        "                             format(avg_duration/60)].apply \\\n",
        "                             (lambda x: set_duration_criteria(x))\n",
        "\n",
        "if survey_type == 'qual':\n",
        "  # Getting a list of all the questions in the survey\n",
        "  questions = df.columns[list(df.columns).index(\"UserLanguage\")+1: \\\n",
        "                       list(df.columns).index(\"responseId\")]\n",
        "else:\n",
        "  # Getting a list of all the questions in the survey\n",
        "  r = re.compile(\"Q\\d.*\")\n",
        "  questions = list(filter(r.match, df.columns))\n",
        "\n",
        "# Calculate the number of questions for each record\n",
        "for idx in range(len(df)):\n",
        "  if idx != 0:   \n",
        "    cnt = 0\n",
        "    for q in questions:\n",
        "      if pd.isnull(df.loc[idx, q]) == False:\n",
        "        cnt = cnt + 1\n",
        "    df.at[idx, \"Number of Questions Answered\"] = cnt\n",
        "\n",
        "# Calculating the number of brands in a questions\n",
        "answers = []\n",
        "\n",
        "# If there are any brands questions\n",
        "if (len(brands_questions) > 0):\n",
        "# Loop over the questions in brands questions\n",
        "  for q in brands_questions:\n",
        "    \n",
        "    # If the question exists in the survey questions with the same name,\n",
        "    # it means that all the brands are going to be in the same cell,\n",
        "    # divided by a comma\n",
        "    \n",
        "    if (q in df.columns):\n",
        "      for idx, row in df.iterrows():\n",
        "        try:\n",
        "          df.at[idx, \"Number_of_brands_in_{}\".format(q)] = \\\n",
        "            df.at[idx, q].count(\",\")+1\n",
        "        except:\n",
        "          None\n",
        "    \n",
        "    # If the questions does not exist with the same name, it means it contains\n",
        "    # and underscore, e.g. Q1 in the brands questions and in the survey itself,\n",
        "    # it is Q1_1, Q1_2, etc. This means the brands are going to be in different \n",
        "    # columns in this case  \n",
        "    else:\n",
        "      for idx, row1 in df.iterrows():\n",
        "        for row2 in df:\n",
        "          if (q in row2):\n",
        "            if (isinstance(df.at[idx, \"{}\".format(row2)], str) or \\\n",
        "                isinstance(df.at[idx, \"{}\".format(row2)], int)):\n",
        "              answers.append(df.at[idx, \"{}\".format(row2)])\n",
        "        if(len(answers)>0):\n",
        "          df.at[idx, \"Number_of_brands_in_{}\".format(q)] = str(len(answers))\n",
        "          answers = []\n",
        "\n",
        "if survey_type == 'inc':\n",
        "  # Get all questions in text_questions\n",
        "  # e.g if the user enters 'Q42' in the text questions, this would extract all of\n",
        "  # 'Q42' such as 'Q42_1', 'Q42_2', 'Q42_3', etc\n",
        "  new_text_questions = []\n",
        "  for q in text_questions:\n",
        "    for q2 in questions:\n",
        "      if q in q2:\n",
        "        new_text_questions.append(q2)\n",
        "  text_questions = new_text_questions\n",
        "\n",
        "### new text comparison\n",
        "#create dictionaries to store the texts, lengths, and tensors\n",
        "text_dict = {}\n",
        "ten_dict = {}\n",
        "len_cond = {}\n",
        "\n",
        "#check if any text questions:\n",
        "length_text = len(text_questions)\n",
        "if length_text > 0:\n",
        "  #for every question in the list:\n",
        "  for k in range(length_text):\n",
        "    q_in_q = text_questions[k]\n",
        "    #create an entry in the different dictionaries for them\n",
        "    text_dict[q_in_q] = []\n",
        "    len_cond[q_in_q] = []\n",
        "    #check each survey answer for the text question, to actually make sure it is text, and if it's empty replace the Nonetype object with N/A\n",
        "    for i in list(df[q_in_q]):\n",
        "      #pass through cleaner\n",
        "      j = clean_text(i)\n",
        "      #check if empty\n",
        "      if j is None:\n",
        "        #append 0 length and N/A string\n",
        "        text_dict[q_in_q].append(\"N/A\")\n",
        "        len_cond[q_in_q].append(0)\n",
        "      #otherwise append it's length and the clean text\n",
        "      else:\n",
        "        txt_len = len(j.split())\n",
        "        text_dict[q_in_q].append(j)\n",
        "        if txt_len >= 4:\n",
        "          len_cond[q_in_q].append(1)\n",
        "        else:\n",
        "          len_cond[q_in_q].append(0)\n",
        "    \n",
        "    #encode through model the list of strings\n",
        "    qq = text_dict[q_in_q]\n",
        "    emb_qq = model.encode(qq, convert_to_tensor=True)\n",
        "    ten_dict[q_in_q] = emb_qq\n",
        "\n",
        "#create dictionary where we'll append the cosine scores \n",
        "cos_dict = {}\n",
        "coscount = 0\n",
        "whilecount = 0\n",
        "lenmat_dict = {}\n",
        "#if there are text questions:\n",
        "if length_text > 0:\n",
        "  #while there are elements to compare against:\n",
        "  while whilecount <= (length_text - 1):\n",
        "    #set base question\n",
        "    base_q = text_questions[whilecount]\n",
        "    #compare through all remaining elements in the list of text questions\n",
        "    while coscount <= (length_text - 1):\n",
        "      #check cosine similarities\n",
        "      comp_q = text_questions[coscount]\n",
        "      key = [base_q, comp_q]\n",
        "      cos_score = util.cos_sim(ten_dict[key[0]],ten_dict[key[1]])\n",
        "      cos_dict[tuple(key)] = cos_score\n",
        "      coscount += 1\n",
        "      #creating the conditional length matrix\n",
        "      a = np.array(len_cond[base_q])\n",
        "      b = np.array(len_cond[comp_q])\n",
        "      ab = np.outer(a,b)\n",
        "      lenmat_dict[tuple(key)] = ab\n",
        "\n",
        "    #add one to the whilecount, ie select next element in the list of text_questions as base_q, and set the first element to be compared to be itself\n",
        "    whilecount += 1\n",
        "    coscount = whilecount\n",
        "\n",
        "#we are now going to select only elements having higher than a certain score, ie text that a similar, and we are going to include the length check\n",
        "#for every key pair of questions in the cosine dictionary\n",
        "for key in cos_dict:\n",
        "  #get values\n",
        "  mat = cos_dict[key].numpy()\n",
        "  len_mat = lenmat_dict[key]\n",
        "  #get elements higher than a certain threshold\n",
        "  cos_cond = (mat >= 0.95).astype(int)\n",
        "  #multiply both matrices element wise to satisfy both conditions\n",
        "  condition = np.multiply(len_mat,cos_cond)\n",
        "  #get indices of the elements\n",
        "  higher = np.transpose(condition.nonzero())\n",
        "  #check if we are comparing a question with itself, if so don't pay attention to text answers being compared with themselves, since score will be 1\n",
        "  if key[0] == key[1]:\n",
        "    for i in higher:\n",
        "      prim = i[0]\n",
        "      sec = i[1]\n",
        "      if (prim != sec):\n",
        "        color_cell(int(prim)+1, key[0], \"yellow\")\n",
        "        df.at[int(prim)+1, \"Duplication_Within_Survey in {}\".format(key[0])] = \"Duplication from record number {} in {}\".format(int(sec)+3, key[1])\n",
        "  else:\n",
        "    for i in higher:\n",
        "      prim = i[0]\n",
        "      sec = i[1]\n",
        "      color_cell(int(prim)+1, key[0], \"yellow\") \n",
        "      df.at[int(prim)+1, \"Duplication_Within_Survey in {}\".format(key[0])] = \"Duplication from record number {} in {}\".format(int(sec)+3, key[1])\n",
        "      \n",
        "      \n",
        "\n",
        "# Checking the straighlining criteria\n",
        "answers = []\n",
        "if (len(straightlineing_questions) > 0):\n",
        "  for idx, row1 in df.iterrows():\n",
        "    for q in straightlineing_questions:\n",
        "      # Making sure it is not a text question\n",
        "      if (\"TEXT\" not in q):\n",
        "        for row2 in df:\n",
        "          if (q in row2):\n",
        "            # Making sure the answer is either a str or an int\n",
        "            if (isinstance(df.at[idx, \"{}\".format(row2)], str) or \\\n",
        "                isinstance(df.at[idx, \"{}\".format(row2)], int)):\n",
        "              # Append the answer to the answers list\n",
        "              answers.append(df.at[idx, \"{}\".format(row2)])\n",
        "        # If the list is not empty\n",
        "        if(len(answers)>0):\n",
        "          # Calcualte the straightlining percentage \n",
        "          df.at[idx, \"Straightlineing_in_{}\".format(q)] = \\\n",
        "          str(math.floor(straightline(answers) / len(answers) * 100)) + \"%\"\n",
        "          # Checking if the straighlining percentage is more than 90%\n",
        "          if math.floor(straightline(answers) / len(answers) * 100) >= 90:\n",
        "            for row2 in df:\n",
        "              # Making sure question name does not inculde Hq or HQ, and then\n",
        "              # highlight all the cells straighlines\n",
        "              if (q in row2 and \"Hq\" not in row2 and \"HQ\" not in row2):\n",
        "                color_cell(idx, row2, \"#9bdfd4\")\n",
        "        answers = []\n",
        "\n",
        "# Checking the outliers criteria\n",
        "if(len(outliers_questions) > 0):\n",
        "  for q in outliers_questions:\n",
        "    if q in df.columns:\n",
        "      q_low = df[\"{}\".format(q)].quantile(0.01)\n",
        "      q_hi  = df[\"{}\".format(q)].quantile(0.99)\n",
        "      for idx, row in enumerate(questions):\n",
        "        idx = idx + 1\n",
        "        if df.at[idx, q] > q_hi or df.at[idx, q] < q_low:\n",
        "          df.at[idx, \"Outliers_in_{}\".format(q)] = \"True\"\n",
        "\n",
        "# Checking the Duration Strike based on the threshold the user entered\n",
        "for idx, row in df.iterrows():\n",
        "  if df.at[idx, \"Duration (in minutes)\"] < min_duration_allowed_in_mins:\n",
        "    df.at[idx, \"Duration_Strike\"] = 1\n",
        "  elif df.at[idx, \"Duration (in minutes)\"] > max_duration_allowed_in_mins:\n",
        "    df.at[idx, \"Duration_Strike\"] = 2\n",
        "  else:\n",
        "    df.at[idx, \"Duration_Strike\"] = 0\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Aggregating all our past findings in new columns:\n",
        "Straightlined_questions > Number of questions a user straighlined\n",
        "Duplicated_Questions > Number of questions a user duplicated\n",
        "Duplication_Percentage > The percentage of the questions a user puplicated\n",
        "Outliers_Questions > Number of questions a user entered an outlier value\n",
        "\"\"\"\n",
        "\n",
        "if (len(straightlineing_questions) > 0):\n",
        "  straightlines = 0\n",
        "  for idx, row in df.iterrows():\n",
        "    for q in df.columns:\n",
        "      if \"Straightlineing\" in q:\n",
        "        try:\n",
        "          if (int(df.at[idx, q].replace(\"%\", \"\")) >= 90):\n",
        "            straightlines = straightlines + 1\n",
        "        except:\n",
        "          None\n",
        "    df.at[idx, \"Straightlined_Questions\"] = straightlines\n",
        "    straightlines = 0\n",
        "\n",
        "\n",
        "if (len(text_questions) > 0):\n",
        "  c = 0\n",
        "  for idx in range(len(df)):\n",
        "    idx = idx + 1\n",
        "    for q in df.columns:\n",
        "      if \"Duplication\" in q:\n",
        "        if isinstance(df.at[idx, q], str):\n",
        "          c = c+1\n",
        "    df.at[idx, \"Duplicated_Questions\"] = c\n",
        "    c = 0\n",
        "\n",
        "\n",
        "# Calculating the Duplication percentages of the duplicated questions to\n",
        "# all of the text questions\n",
        "if \"Duplication_Questions\" in df.columns:\n",
        "  df[\"Duplication_Percentage\"] = df[\"Duplication_Questions\"] / \\\n",
        "                                 len(text_questions)*100\n",
        "\n",
        "if (len(outliers_questions) > 0):\n",
        "  c = 0\n",
        "  for idx in range(len(df)):\n",
        "    idx = idx + 1\n",
        "    for q in df.columns:\n",
        "      if \"Outliers\" in q:\n",
        "        if isinstance(df.at[idx, q], str) and df.at[idx, q] == \"True\":\n",
        "          c = c+1\n",
        "    df.at[idx, \"Outliers_Questions\"] = c\n",
        "    c = 0\n",
        "\n",
        "# Calculating the Final Score based on all of the above criterias\n",
        "for idx in range(len(df)+1):\n",
        "  if(idx != 0):\n",
        "    cnt = 0\n",
        "    comments = []\n",
        "    for q in df.columns:\n",
        "      if q in ['Straightlined_Questions', \\\n",
        "               'Duplicated_Questions', 'Outliers_Questions']:\n",
        "        if isinstance(df.at[idx, q], float):\n",
        "          cnt = cnt + df.at[idx, q]\n",
        "          if (df.at[idx, q] > 0):\n",
        "            comments.append(q)\n",
        "      elif q == \"Duration_Strike\":\n",
        "        if df.at[idx, q] == 1:\n",
        "          cnt = cnt + 1\n",
        "          comments.append(q + ' +100')\n",
        "        elif df.at[idx, q] == 2:\n",
        "          cnt = cnt + 1\n",
        "          comments.append(q + ' +30')\n",
        "      elif q == \"Risk Rating\":\n",
        "        if df.at[idx, q] == 'HIGH':\n",
        "          cnt = cnt + 1\n",
        "          comments.append(q)\n",
        "      elif q == \"User IP Countries\":\n",
        "        if not pd.isnull(df.at[idx, q]) and df.at[idx, q].count(',') >= 1:\n",
        "          cnt = cnt + 1\n",
        "          comments.append(q)\n",
        "      #elif q == \"Shared IP Users\":\n",
        "        #if not pd.isnull(df.at[idx, q]) and df.at[idx, q].count(',') >= 3:\n",
        "          #cnt = cnt + 1\n",
        "          #comments.append(q)\n",
        "      elif q == \"Shared PayPal Account\":\n",
        "        if not pd.isnull(df.at[idx, q]) and df.at[idx, q].count(',') >= 1:\n",
        "          cnt = cnt + 1\n",
        "          comments.append(q)\n",
        "      #elif q == \"Shared PayPal Account\":\n",
        "        #if not df.at[idx, q] > 1:\n",
        "          #cnt = cnt + 1\n",
        "          #comments.append(q)\n",
        "      elif q == \"Honesty rating\":\n",
        "        if not pd.isnull(df.at[idx, q]) and \\\n",
        "          df.at[idx, q] < 10 and \\\n",
        "          (df.at[idx, \"Lifetime Accepted Count\"] + \\\n",
        "          df.at[idx, \"Lifetime Disqualification Count\"]) < 10: \n",
        "          cnt = cnt + 1\n",
        "          comments.append(q)\n",
        "      elif q == \"User VPN Usage Count\":\n",
        "        #if not pd.isnull(df.at[idx, q]):\n",
        "        if (df.at[idx, q] > 50):\n",
        "          cnt = cnt + 1\n",
        "          comments.append(q)\n",
        "\n",
        "    df.at[idx, \"Final_Score\"] = cnt\n",
        "    df.at[idx, \"Comments\"] = str(comments)\n",
        "\n",
        "# calculating the Risk Score\n",
        "\n",
        "for idx in range(len(df)+1):\n",
        "  if(idx != 0):\n",
        "    cnt = 0\n",
        "    for q in df.columns:\n",
        "      if q == 'Duration (in minutes)':\n",
        "        if df.at[idx, q] < min_duration_allowed_in_mins:\n",
        "          cnt = cnt + 100\n",
        "        elif df.at[idx, q] > max_duration_allowed_in_mins:\n",
        "          cnt = cnt + 30\n",
        "      elif q == 'Straightlined_Questions':\n",
        "        if df.at[idx, q] >= 1:\n",
        "          cnt = cnt + 40\n",
        "      elif q == 'Duplicated_Questions':\n",
        "        if df.at[idx, q] >= 1:\n",
        "          cnt = cnt + 100\n",
        "      elif q == 'Risk Rating':\n",
        "        if df.at[idx, q] == 'HIGH':\n",
        "          cnt = cnt + 20\n",
        "      elif q == 'User IP Countries':\n",
        "        if not pd.isnull(df.at[idx, q]) and df.at[idx, q].count(',') >= 1:\n",
        "          cnt = cnt + 50\n",
        "      #elif q == 'Shared IP Users':\n",
        "        #if not pd.isnull(df.at[idx, q]) and df.at[idx, q].count(',') >= 3:\n",
        "          #cnt = cnt + 20\n",
        "      elif q == 'Shared PayPal Account':\n",
        "        if not pd.isnull(df.at[idx, q]):\n",
        "          accs = df.at[idx, q].count(',')+1\n",
        "          if accs > 1:\n",
        "            cnt = cnt + 100\n",
        "      #elif q == 'Shared PayPal Account':\n",
        "        #if not df.at[idx, q] > 1:      \n",
        "          #cnt = cnt + 100 \n",
        "      elif q == \"Honesty rating\":\n",
        "        if not pd.isnull(df.at[idx, q]) and \\\n",
        "          df.at[idx, q] < 10 and \\\n",
        "          (df.at[idx, \"Lifetime Accepted Count\"] + \\\n",
        "          df.at[idx, \"Lifetime Disqualification Count\"]) < 10:\n",
        "          cnt = cnt + 10\n",
        "      elif q == \"User VPN Usage Count\":\n",
        "        #if not pd.isnull(df.at[idx, q]):\n",
        "          #if (df.at[idx, q] >= 10 and df.at[idx, q] <= 20):\n",
        "            #cnt = cnt + 20\n",
        "          #if (df.at[idx, q] > 20 and df.at[idx, q] <= 51):\n",
        "            #cnt = cnt + 30\n",
        "        if (df.at[idx, q] >= 50):\n",
        "          cnt = cnt + 100\n",
        "    # Risk Score cannot exceed 100%\n",
        "    if cnt > 100:\n",
        "      cnt = 100\n",
        "    df.at[idx, \"Risk_Score\"] = str(cnt)+'%'\n",
        "    if cnt >= 100:\n",
        "      color_cell(idx, \"Risk_Score\", \"red\")\n",
        "\n",
        "\n",
        "\n",
        "# Highlight the records disqualified by screeners aka 'gc' = 0 \n",
        "for idx in range(len(df)+1):\n",
        "  if(idx != 0):\n",
        "    if df.at[idx, \"gc\"] == '0':\n",
        "      df.at[idx, \"Risk_Score\"] = \"Disqualified by Screeners\"\n",
        "      color_cell(idx, \"Risk_Score\", \"orange\")\n",
        "\n",
        "# Highlighting records with Honesty Rating less than 51\n",
        "for idx in range(len(df)+1):\n",
        "  if(idx != 0):\n",
        "    try:\n",
        "      if df.at[idx, \"User Honesty Rating\"] < 51:\n",
        "        color_cell(idx, \"User Honesty Rating\", \"yellow\")\n",
        "    except:\n",
        "      None\n",
        "\n",
        "# Highliting Good and Bad users\n",
        "for idx in range(len(df)+1):\n",
        "  if(idx != 0):\n",
        "    try:\n",
        "      if df.at[idx, \"user_status\"] == 'Good':\n",
        "        color_cell(idx, \"User Id\", \"green\")\n",
        "        color_cell(idx, \"user_name\", \"green\")\n",
        "        color_cell(idx, \"user_status\", \"green\")\n",
        "      elif df.at[idx, \"user_status\"] == 'Bad':\n",
        "        color_cell(idx, \"User Id\", \"red\")\n",
        "        color_cell(idx, \"user_name\", \"red\")\n",
        "        color_cell(idx, \"user_statsu\", \"red\")\n",
        "    except:\n",
        "      None\n",
        "\n",
        "\n",
        "# Highlight the columns headers accordingly\n",
        "for col in df.columns:\n",
        "  if col in [\"Country Check\", \"Duration (in minutes)\", \"Pulse Action\", \\\n",
        "             \"Action to Client\", \"Reason\"]:\n",
        "    color_cell(0, col, \"#FFCCCB\")\n",
        "  elif col in pulse_cols:\n",
        "    color_cell(0, col, \"#ADD8E6\")\n",
        "  else:\n",
        "    color_cell(0, col, \"#D3D3D3\")\n",
        "color_cell(0, \"Response Id\", \"#ADD8E6\")\n",
        "\n",
        "# new update - Fill Action to Client & Reason in case of gc=0 or speeder\n",
        "# gc = 0\n",
        "for idx in range(len(df)+1):\n",
        "  if(idx != 0):\n",
        "    if df.at[idx, \"gc\"] == '0':\n",
        "      df.at[idx, \"Action to Client\"] = \"Rejected by Script\"\n",
        "      df.at[idx, \"Reason\"] = \"gc=0\"\n",
        "# speeder\n",
        "for idx in range(len(df)+1):\n",
        "  if(idx != 0):\n",
        "    if df.at[idx, \"Duration (in minutes)\"] < min_duration_allowed_in_mins:\n",
        "      df.at[idx, \"Action to Client\"] = \"Rejected by Script\"\n",
        "      df.at[idx, \"Reason\"] = \"speeder\"\n",
        "\n",
        "\n",
        "\n",
        "df[\"Risk_Score_\"] = df[\"Risk_Score\"]\n",
        "df[\"Comments_\"] = df[\"Comments\"]\n",
        "\n",
        "\n",
        "\n",
        "# Append the question row we removed at the start to the dataframe again\n",
        "df = pd.DataFrame(questions_row.to_dict(), index = [0]).append(df)\n",
        "\n",
        "df = move_column(df, 39, \"Risk_Score_\")\n",
        "df = move_column(df, 39, \"Comments_\")\n",
        "\n",
        "\n",
        "# Applying the styling to the dataframe\n",
        "df1 = df1.reindex(columns = df.columns)\n",
        "# to avoid float error\n",
        "df = df.fillna(\"\")\n",
        "df1 = df1.fillna(\"\")\n",
        "df = df.style.apply(return_df1, axis=None)\n",
        "\n",
        "## new part to test\n",
        "#df.to_excel(\"master_clean.xlsx\", sheet_name = \"master\")\n",
        "#FilePath = \"master_clean.xlsx\"\n",
        "#ExcelWorkbook = load_workbook(FilePath)\n",
        "#writer = pd.ExcelWriter(FilePath, engine = 'openpyxl')\n",
        "#writer.book = ExcelWorkbook\n",
        "#writer.save()\n",
        "\n",
        "xlwriter = pd.ExcelWriter('master_clean.xlsx')\n",
        "df.to_excel(xlwriter, sheet_name = 'master', index = False)\n",
        "df_main.to_excel(xlwriter, sheet_name = 'main task', index = False)\n",
        "df_call.to_excel(xlwriter, sheet_name = 'call task', index = False)\n",
        "df_users.to_excel(xlwriter, sheet_name = 'users', index = False)\n",
        "\n",
        "xlwriter.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARIqY81nhjU0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}